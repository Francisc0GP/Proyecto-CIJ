{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataconn():\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que crea una conexion a la base de datos de SQL Server\n",
    "    Retorna:\n",
    "    connection: Conexion a la base de datos de SQL Server\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    server = os.getenv('DB_SERVER')\n",
    "    database = os.getenv('DB_DATABASE')\n",
    "    username = os.getenv('DB_USER')\n",
    "    password = os.getenv('DB_PASSWORD')\n",
    "    connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "    return connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_consult():\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que lee el archivo consult.sql y retorna el contenido del archivo\n",
    "    Retorna:\n",
    "    consult: Contenido del archivo consult.sql\n",
    "    \"\"\"\n",
    "    with open ('consults/consultH.sql', 'r') as file:\n",
    "        consult = file.read()\n",
    "    return consult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(connection_string):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que realiza una consulta a la base de datos de SQL Server y retorna un DataFrame con los resultados\n",
    "    Retorna:\n",
    "    df: DataFrame con los resultados de la consulta\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        cursor = conn.cursor()\n",
    "        query = read_consult()\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_TCEJEI(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y TCEJEI_FormatoTrastornoClinicoEjeIId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y TCEJEI_FormatoTrastornoClinicoEjeIId\n",
    "    \"\"\"\n",
    "\n",
    "    grupo = df.groupby([\"FolioId\", \"TCEJEI_FormatoTrastornoClinicoEjeIId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_TCEJEII(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y TCEJEII_FormatoTrastornoClinicoEjeIIId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y TCEJEII_FormatoTrastornoClinicoEjeIIId\n",
    "    \"\"\"\n",
    "    \n",
    "    grupo = df.groupby([\"FolioId\", \"TCEJEII_FormatoTrastornoClinicoEjeIIId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_TCEJEIII(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y TCEJEIII_FormatoTrastornoClinicoEjeIIIId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y TCEJEIII_FormatoTrastornoClinicoEjeIIIId\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\", \"TCEJEIII_FormatoTrastornoClinicoEjeIIIId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_TCEJEIV(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y TCEJEIV_FormatoTrastornoClinicoEjeIVId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y TCEJEIV_FormatoTrastornoClinicoEjeIV\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\", \"TCEJEIV_FormatoTrastornoClinicoEjeIVId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_HCEF(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y HCEF_FormatoExploracionFisicaId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y HCEF_FormatoExploracionFisicaId\n",
    "    \"\"\"\n",
    "    \n",
    "    grupo = df.groupby([\"FolioId\", \"HCEF_FormatoExploracionFisicaId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_HCMA(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y HCMA_FormatoMetodosAnticonceptivosId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y HCMA_FormatoMetodosAnticonceptivosId\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\", \"HCMA_FormatoMetodosAnticonceptivosId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_HCPRO(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y HCPRO_FormatoPronosticoId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y HCPRO_FormatoPronosticoId\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\", \"HCPRO_FormatoPronosticoId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grupo_Folio_HCID(df):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que agrupa los registros por FolioId y HCID_FormatoImpresionDiagnosticaId\n",
    "    Parametros:\n",
    "    df: DataFrame con los registros a agrupar\n",
    "    Retorna:\n",
    "    grupo: DataFrame agrupado por FolioId y HCID_FormatoImpresionDiagnosticaId\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\", \"HCID_FormatoImpresionDiagnosticaId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows (group_sep):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función elimina las filas duplicadas de un DataFrame de pandas agrupado por FolioId y SustanciaId.\n",
    "    Parametros:\n",
    "    group_sep: DataFrame de pandas\n",
    "    Return:\n",
    "    group_sep: DataFrame de pandas sin filas duplicadas\n",
    "    \"\"\"\n",
    "    group_sep.drop_duplicates( subset = \"FolioId\" , keep = \"first\" , inplace = True)\n",
    "    return group_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piv (grupo_mod , list_columns):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función realiza una tabla pivote de un DataFrame de pandas agrupado por FolioId y SustanciaId.\n",
    "    Parametros:\n",
    "    grupo_mod: DataFrame de pandas\n",
    "    list_columns: lista de columnas a procesar\n",
    "    Return:\n",
    "    df_complete: DataFrame de pandas con tabla pivote\n",
    "    \"\"\"\n",
    "    \n",
    "    df_complete = pd.DataFrame()\n",
    "    for valor , group_sep in grupo_mod.groupby(\"FolioId\"):\n",
    "        for i in range(len(group_sep.index)):\n",
    "            for col in list_columns:\n",
    "                if i != 0 :\n",
    "                    aux_name_col = col + str(i)\n",
    "                    if aux_name_col not in group_sep.columns:\n",
    "                        group_sep[aux_name_col] = np.nan\n",
    "                    group_sep[aux_name_col] = group_sep[col].iloc[i]\n",
    "        df_complete = pd.concat([df_complete, group_sep])\n",
    "    return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract (x):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función extrae el primer elemento de una lista.\n",
    "    Parametros:\n",
    "    x: lista\n",
    "    Return:\n",
    "    x[0]: primer elemento de la lista\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(x , list):\n",
    "        return x[0] if len(x) > 0 else None\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trat (df_completemerge):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función aplica la función extract a todas las columnas de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    Return:\n",
    "    df_completemerge: DataFrame de pandas con la función extract aplicada a todas las columnas\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df_completemerge.columns:\n",
    "        df_completemerge[col] = df_completemerge[col].apply(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_Folio( df_completemerge, val_folio , ind_folio):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función busca el índice de un valor en una columna de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    val_folio: valor a buscar\n",
    "    ind_folio: índice a buscar\n",
    "    Return:\n",
    "    ind: índice del valor en la columna\n",
    "    \"\"\"\n",
    "    \n",
    "    for ind , val in df_completemerge[\"FolioId\"].items():\n",
    "        if val == val_folio and ind != ind_folio:\n",
    "            return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AcomDa (df_completemerge , ind , ind_igual):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función acomoda los valores de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    ind: índice a acomodar\n",
    "    ind_igual: índice a acomodar\n",
    "    Return:\n",
    "    df_completemerge: DataFrame de pandas acomodado\n",
    "    \"\"\"\n",
    "    \n",
    "    if ind_igual == None:\n",
    "        return df_completemerge\n",
    "    else:\n",
    "        for col in df_completemerge.columns:\n",
    "            valor_1 = df_completemerge[col].iloc[ind]\n",
    "            valor_2 = df_completemerge[col].iloc[ind_igual]\n",
    "            if pd.isna(valor_1) and pd.notna(valor_2):\n",
    "                df_completemerge[col].iloc[ind] = valor_2\n",
    "            elif pd.notna(valor_1) and pd.isna(valor_2):\n",
    "                df_completemerge[col].iloc[ind_igual] = valor_1\n",
    "        return df_completemerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limp (df_completemerge):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función elimina los valores duplicados de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    Return:\n",
    "    df_new: DataFrame de pandas sin valores duplicados\n",
    "    \"\"\"\n",
    "    \n",
    "    for ind , val in df_completemerge[\"FolioId\"].items():\n",
    "        ind_igual = busqueda_Folio(df_completemerge , val , ind)\n",
    "        df_new = AcomDa(df_completemerge , ind , ind_igual)\n",
    "    df_new.drop_duplicates(inplace = True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función es la principal y ejecuta las funciones anteriores.\n",
    "    Parametros:\n",
    "    df: DataFrame de pandas\n",
    "    Return:\n",
    "    df_new: DataFrame de pandas sin valores duplicados\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grupo = Grupo_Folio_TCEJEI(df)\n",
    "    trat(grupo)\n",
    "    list_columns = [\"TCEJEI_FormatoTrastornoClinicoEjeIId\", \"TCEJEI_FormatoImpresionDiagnosticaId\", \"TCEJEI_CodigoCompuesto\",\"TCEJEI_ComunNomenclaturaId\", \"TCEJEI_ComunConsumoId\", \"TCEJEI_Especifique\"]\n",
    "    df_complete = piv(grupo , list_columns)\n",
    "    df_complete = limp(df_complete)\n",
    "\n",
    "    grupo2 = Grupo_Folio_TCEJEII(df)\n",
    "    trat(grupo2)\n",
    "    list_columns = [\"TCEJEII_FormatoTrastornoClinicoEjeIIId\", \"TCEJEII_FormatoImpresionDiagnosticaId\", \"TCEJEII_CodigoCompuesto\", \"TCEJEII_ComunNomenclaturaId\", \"TCEJEII_Especifique\"]\n",
    "    df_complete2 = piv(grupo2 , list_columns)\n",
    "    df_complete2 = limp(df_complete2)\n",
    "\n",
    "    grupo3 = Grupo_Folio_TCEJEIII(df)\n",
    "    trat(grupo3)\n",
    "    list_columns = [\"TCEJEIII_FormatoTrastornoClinicoEjeIIIId\", \"TCEJEIII_FormatoImpresionDiagnosticaId\", \"TCEJEIII_CodigoCompuesto\", \"TCEJEIII_ComunNomenclaturaId\",\"TCEJEIII_ComunConsumoId\" , \"TCEJEIII_Especifique\"]\n",
    "    df_complete3 = piv(grupo3 , list_columns)\n",
    "    df_complete3 = limp(df_complete3)\n",
    "\n",
    "    grupo4 = Grupo_Folio_TCEJEIV(df)\n",
    "    trat(grupo4)\n",
    "    list_columns = [\"TCEJEIV_FormatoTrastornoClinicoEjeIVId\", \"TCEJEIV_FormatoImpresionDiagnosticaId\", \"TCEJEIV_Codigo\" ,\"TCEJEIV_ComunNomenclaturaId\",\"TCEJEIV_ComunConsumoId\", \"TCEJEIV_Especifique\"]\n",
    "    df_complete4 = piv(grupo4 , list_columns)\n",
    "    df_complete4 = limp(df_complete4)\n",
    "\n",
    "    grupo5 = Grupo_Folio_HCEF(df)\n",
    "    trat(grupo5)\n",
    "    list_columns = [\"HCEF_FormatoExploracionFisicaId\", \"HCEF_FormatoId\", \"HCEF_SignosVitalesPeso\", \"HCEF_SignosVitalesTalla\", \"HCEF_SignosVitalesIMCComunId\", \"HCEF_SignosVitalesFC\", \"HCEF_SignosVitalesFR\", \"HCEF_SignosVitalesPulso\", \"HCEF_SignosVitalesTA\", \"HCEF_SignosVitalesTAHg\", \"HCEF_SignosVitalesTemperatura\", \"HCEF_HabitusExterior\", \"HCEF_ExploracionEspecializadaComunId\", \"HCEF_ExploracionEspecializadaCuales\" ]\n",
    "    df_complete5 = piv(grupo5 , list_columns)\n",
    "    df_complete5 = limp(df_complete5)\n",
    "    \n",
    "    grupo6 = Grupo_Folio_HCMA(df)\n",
    "    trat(grupo6)\n",
    "    list_columns = [\"HCMA_FormatoMetodosAnticonceptivosId\", \"HCMA_FormatoId\", \"HCMA_ComunMetodoAnticonceptivoId\"]\n",
    "    df_complete6 = piv(grupo6 , list_columns)\n",
    "    df_complete6 = limp(df_complete6)\n",
    "    \n",
    "    grupo7 = Grupo_Folio_HCPRO(df)\n",
    "    trat(grupo7)\n",
    "    list_columns = [\"HCPRO_FormatoPronosticoId\",\"HCPROFormatoId\", \"HCPRO_ParaVidaId\", \"HCPRO_ParaFuncionId\", \"HCPRO_ParaVidaFuncionId\", \"HCPRO_Observaciones\"]\n",
    "    df_complete7 = piv(grupo7 , list_columns)\n",
    "    df_complete7 = limp(df_complete7)\n",
    "\n",
    "    grupo8 = Grupo_Folio_HCID(df)\n",
    "    trat(grupo8)\n",
    "    list_columns = [\"HCID_FormatoImpresionDiagnosticaId\", \"HCID_FormatoId\", \"HCID_DiagnosticoTrastornoClinicoEjeI\", \"HCID_DiagnosticoTrastornoClinicoEjeII\", \"HCID_DiagnosticoTrastornoClinicoEjeIII\", \"HCID_DiagnosticoTrastornoClinicoEjeIV\" , \"HCID_PeriodoReferidoComunId\"]\n",
    "    df_complete8 = piv(grupo8 , list_columns)\n",
    "    df_complete8 = limp(df_complete)\n",
    "\n",
    "    df_complete = pd.concat([df_complete, df_complete2, df_complete3, df_complete4, df_complete5, df_complete6, df_complete7, df_complete8], ignore_index=True) \n",
    "    trat(df_complete)\n",
    "    df_complete = limp(df_complete)\n",
    "    drop_rows(df_complete)\n",
    "    return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = get_dataconn()\n",
    "df = get_dataset(connection_string)\n",
    "df.to_csv('dataset/SQLHistoriaClinica.csv', index = False)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_final = pd.DataFrame()\n",
    "chunksize = 100\n",
    "000\n",
    "for chunk in pd.read_csv(\"results/HistoriaClinica.csv\", chunksize=chunksize):\n",
    "    df = chunk \n",
    "    df = main(df)\n",
    "    df_final = pd.concat([df_final, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"BSD_HistoriaClinica2021_2023M.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
