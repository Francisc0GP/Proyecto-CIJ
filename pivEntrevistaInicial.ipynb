{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataconn():\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que crea una conexion a la base de datos de SQL Server\n",
    "    Retorna:\n",
    "    connection: Conexion a la base de datos de SQL Server\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    server = os.getenv('DB_SERVER')\n",
    "    database = os.getenv('DB_DATABASE')\n",
    "    username = os.getenv('DB_USER')\n",
    "    password = os.getenv('DB_PASSWORD')\n",
    "    connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "    return connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_consult():\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que lee el archivo consult.sql y retorna el contenido del archivo\n",
    "    Retorna:\n",
    "    consult: Contenido del archivo consult.sql\n",
    "    \"\"\"\n",
    "    with open ('consults/consult.sql', 'r') as file:\n",
    "        consult = file.read()\n",
    "    return consult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(connection_string):\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "    Funcion que realiza una consulta a la base de datos de SQL Server y retorna un DataFrame con los resultados\n",
    "    Retorna:\n",
    "    df: DataFrame con los resultados de la consulta\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        cursor = conn.cursor()\n",
    "        query = read_consult()\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupFolioSustancia(df):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función agrupa por FolioId y SustanciaId y regresa una lista de los valores de las columnas agrupadas. \n",
    "    Parametros:\n",
    "    df: DataFrame de pandas\n",
    "    Return:\n",
    "    grupo: DataFrame de pandas agrupado por FolioId y SustanciaId\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\" , \"SustanciaId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupFolioMotivo(df):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función agrupa por FolioId y MotivoConsultaId y regresa una lista de los valores de las columnas agrupadas.\n",
    "    Parametros:\n",
    "    df: DataFrame de pandas\n",
    "    Return:\n",
    "    grupo: DataFrame de pandas agrupado por FolioId y MotivoConsultaId\n",
    "    \"\"\"\n",
    "    grupo = df.groupby([\"FolioId\" , \"MotivoConsultaId\"]).agg(list).reset_index()\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar (grupo , list_columns):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función procesa las columnas de un DataFrame de pandas agrupado por FolioId y SustanciaId o MotivoConsultaId.\n",
    "    Parametros:\n",
    "    grupo: DataFrame de pandas \n",
    "    list_columns: lista de columnas a procesar\n",
    "    Return:\n",
    "    grupo: DataFrame de pandas procesado\n",
    "    \"\"\"\n",
    "    for i in range (0 , len(grupo.index)):\n",
    "        for col in list_columns:\n",
    "            if len(grupo[col][i]) > 1:\n",
    "                grupo[col][i] = grupo[col][i][0]\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modif (grupo):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función modifica las columnas de un DataFrame de pandas agrupado por FolioId y SustanciaId o MotivoConsultaId.\n",
    "    Parametros:\n",
    "    grupo: DataFrame de pandas\n",
    "    Return:\n",
    "    grupo: DataFrame de pandas modificado\n",
    "    \"\"\"\n",
    "    \n",
    "    list_columns = [\"EntrevistaInicialSustanciaId\" , \"EdadInicio\" , \"OrdenConsumo\" , \"ComunPrevalenciaId\", \"ComunPrimeraFormaAdministracionId\" , \"ComunSegundaFormaAdministracionId\" , \"ComunTerceraFormaAdministracionId\" , \"ComunAbstinenciaId\" , \"ComunUltimoConsumoId\" , \"Dosis\"]\n",
    "    grupo_pro = procesar(grupo,list_columns)\n",
    "    return grupo_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modif2 (grupo):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función modifica las columnas de un DataFrame de pandas agrupado por FolioId y MotivoConsultaId.\n",
    "    Parametros:\n",
    "    grupo: DataFrame de pandas\n",
    "    Return:\n",
    "    grupo: DataFrame de pandas modificado\n",
    "    \"\"\"\n",
    "    list_columns = [\"MotivoConsultaId\"]\n",
    "    grupo_pro = procesar(grupo,list_columns)\n",
    "    return grupo_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows (group_sep):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función elimina las filas duplicadas de un DataFrame de pandas agrupado por FolioId y SustanciaId.\n",
    "    Parametros:\n",
    "    group_sep: DataFrame de pandas\n",
    "    Return:\n",
    "    group_sep: DataFrame de pandas sin filas duplicadas\n",
    "    \"\"\"\n",
    "    group_sep.drop_duplicates( subset = \"FolioId\" , keep = \"first\" , inplace = True)\n",
    "    return group_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piv (grupo_mod , list_columns):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función realiza una tabla pivote de un DataFrame de pandas agrupado por FolioId y SustanciaId.\n",
    "    Parametros:\n",
    "    grupo_mod: DataFrame de pandas\n",
    "    list_columns: lista de columnas a procesar\n",
    "    Return:\n",
    "    df_complete: DataFrame de pandas con tabla pivote\n",
    "    \"\"\"\n",
    "    \n",
    "    df_complete = pd.DataFrame()\n",
    "    for valor , group_sep in grupo_mod.groupby(\"FolioId\"):\n",
    "        for i in range(len(group_sep.index)):\n",
    "            for col in list_columns:\n",
    "                if i != 0 :\n",
    "                    aux_name_col = col + str(i)\n",
    "                    if aux_name_col not in group_sep.columns:\n",
    "                        group_sep[aux_name_col] = np.nan\n",
    "                    group_sep[aux_name_col] = group_sep[col].iloc[i]\n",
    "        df_complete = pd.concat([df_complete, group_sep])\n",
    "    return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract (x):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función extrae el primer elemento de una lista.\n",
    "    Parametros:\n",
    "    x: lista\n",
    "    Return:\n",
    "    x[0]: primer elemento de la lista\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(x , list):\n",
    "        return x[0] if len(x) > 0 else None\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trat (df_completemerge):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función aplica la función extract a todas las columnas de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df_completemerge.columns:\n",
    "        df_completemerge[col] = df_completemerge[col].apply(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_Folio( df_completemerge, val_folio , ind_folio):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función busca el índice de un valor en una columna de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    val_folio: valor a buscar\n",
    "    ind_folio: índice a buscar\n",
    "    Return:\n",
    "    ind: índice del valor en la columna\n",
    "    \"\"\"\n",
    "    \n",
    "    for ind , val in df_completemerge[\"FolioId\"].items():\n",
    "        if val == val_folio and ind != ind_folio:\n",
    "            return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AcomDa (df_completemerge , ind , ind_igual):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función acomoda los valores de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    ind: índice a acomodar\n",
    "    ind_igual: índice a acomodar\n",
    "    Return:\n",
    "    df_completemerge: DataFrame de pandas acomodado\n",
    "    \"\"\"\n",
    "    \n",
    "    if ind_igual == None:\n",
    "        return df_completemerge\n",
    "    else:\n",
    "        for col in df_completemerge.columns:\n",
    "            valor_1 = df_completemerge[col].iloc[ind]\n",
    "            valor_2 = df_completemerge[col].iloc[ind_igual]\n",
    "            if pd.isna(valor_1) and pd.notna(valor_2):\n",
    "                df_completemerge[col].iloc[ind] = valor_2\n",
    "            elif pd.notna(valor_1) and pd.isna(valor_2):\n",
    "                df_completemerge[col].iloc[ind_igual] = valor_1\n",
    "        return df_completemerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limp (df_completemerge):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función elimina los valores duplicados de un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df_completemerge: DataFrame de pandas\n",
    "    Return:\n",
    "    df_new: DataFrame de pandas sin valores duplicados\n",
    "    \"\"\"\n",
    "    \n",
    "    for ind , val in df_completemerge[\"FolioId\"].items():\n",
    "        ind_igual = busqueda_Folio(df_completemerge , val , ind)\n",
    "        df_new = AcomDa(df_completemerge , ind , ind_igual)\n",
    "    df_new.drop_duplicates(inplace = True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df):\n",
    "    \"\"\"\n",
    "    Descripción:\n",
    "    Esta función aplica todas las funciones anteriores para procesar un DataFrame de pandas.\n",
    "    Parametros:\n",
    "    df: DataFrame de pandas\n",
    "    Return:\n",
    "    df_complete: DataFrame de pandas procesado\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    grupo = groupFolioSustancia(df)\n",
    "    grupo_mod = modif(grupo)\n",
    "    list_columns = [\"SustanciaId\" , \"EntrevistaInicialSustanciaId\" , \"EdadInicio\" , \"OrdenConsumo\" ,\"ComunPrevalenciaId\", \"ComunPrimeraFormaAdministracionId\" , \"ComunSegundaFormaAdministracionId\" , \"ComunTerceraFormaAdministracionId\" , \"ComunAbstinenciaId\" , \"ComunUltimoConsumoId\" , \"Dosis\"]\n",
    "    trat(grupo_mod)\n",
    "    df_complete = piv(grupo_mod,list_columns)\n",
    "    df_complete = limp(df_complete)\n",
    "    drop_rows(df_complete)\n",
    "\n",
    "    grupo2 = groupFolioMotivo(df)\n",
    "    trat(grupo2)\n",
    "    list_columns = [\"MotivoConsultaId\"]\n",
    "    df_complete2 = piv(grupo2,list_columns)\n",
    "    df_complete2 = limp(df_complete2)\n",
    "    drop_rows(df_complete2)\n",
    "    \n",
    "    df_complete = pd.concat([df_complete, df_complete2], ignore_index=True)\n",
    "    trat(df_complete)\n",
    "    df_complete = limp(df_complete)\n",
    "    drop_rows(df_complete)\n",
    "    return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection_string = get_dataconn()\n",
    "#df = get_dataset(connection_string)\n",
    "#df.to_csv('dataset/SQLEntrevistaInicial.csv', index = False)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_final = pd.DataFrame()\n",
    "chunksize = 100000\n",
    "for chunk in pd.read_csv(\"dataset/SQLEntrevistaInicial.csv\", chunksize = chunksize):\n",
    "    df = chunk\n",
    "    df = main(df)\n",
    "    df_final = pd.concat([df_final, df], ignore_index = True)\n",
    "df_final.to_csv('results/EntrevistaInicial.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
